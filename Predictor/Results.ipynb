{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e931b14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "951d184e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"C:/Users/vivek/OneDrive/Documents/FarmersMarket/models/pytorch/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b03c314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Apple Braeburn': 0,\n",
       " 'Apple Crimson Snow': 1,\n",
       " 'Apple Golden 1': 2,\n",
       " 'Apple Golden 2': 3,\n",
       " 'Apple Golden 3': 4,\n",
       " 'Apple Granny Smith': 5,\n",
       " 'Apple Pink Lady': 6,\n",
       " 'Apple Red 1': 7,\n",
       " 'Apple Red 2': 8,\n",
       " 'Apple Red 3': 9,\n",
       " 'Apple Red Delicious': 10,\n",
       " 'Apple Red Yellow 1': 11,\n",
       " 'Apple Red Yellow 2': 12,\n",
       " 'Apricot': 13,\n",
       " 'Avocado': 14,\n",
       " 'Avocado ripe': 15,\n",
       " 'Banana': 16,\n",
       " 'Banana Lady Finger': 17,\n",
       " 'Banana Red': 18,\n",
       " 'Beetroot': 19,\n",
       " 'Blueberry': 20,\n",
       " 'Cactus fruit': 21,\n",
       " 'Cantaloupe 1': 22,\n",
       " 'Cantaloupe 2': 23,\n",
       " 'Carambula': 24,\n",
       " 'Cauliflower': 25,\n",
       " 'Cherry 1': 26,\n",
       " 'Cherry 2': 27,\n",
       " 'Cherry Rainier': 28,\n",
       " 'Cherry Wax Black': 29,\n",
       " 'Cherry Wax Red': 30,\n",
       " 'Cherry Wax Yellow': 31,\n",
       " 'Chestnut': 32,\n",
       " 'Clementine': 33,\n",
       " 'Cocos': 34,\n",
       " 'Corn': 35,\n",
       " 'Corn Husk': 36,\n",
       " 'Cucumber Ripe': 37,\n",
       " 'Cucumber Ripe 2': 38,\n",
       " 'Dates': 39,\n",
       " 'Eggplant': 40,\n",
       " 'Fig': 41,\n",
       " 'Ginger Root': 42,\n",
       " 'Granadilla': 43,\n",
       " 'Grape Blue': 44,\n",
       " 'Grape Pink': 45,\n",
       " 'Grape White': 46,\n",
       " 'Grape White 2': 47,\n",
       " 'Grape White 3': 48,\n",
       " 'Grape White 4': 49,\n",
       " 'Grapefruit Pink': 50,\n",
       " 'Grapefruit White': 51,\n",
       " 'Guava': 52,\n",
       " 'Hazelnut': 53,\n",
       " 'Huckleberry': 54,\n",
       " 'Kaki': 55,\n",
       " 'Kiwi': 56,\n",
       " 'Kohlrabi': 57,\n",
       " 'Kumquats': 58,\n",
       " 'Lemon': 59,\n",
       " 'Lemon Meyer': 60,\n",
       " 'Limes': 61,\n",
       " 'Lychee': 62,\n",
       " 'Mandarine': 63,\n",
       " 'Mango': 64,\n",
       " 'Mango Red': 65,\n",
       " 'Mangostan': 66,\n",
       " 'Maracuja': 67,\n",
       " 'Melon Piel de Sapo': 68,\n",
       " 'Mulberry': 69,\n",
       " 'Nectarine': 70,\n",
       " 'Nectarine Flat': 71,\n",
       " 'Nut Forest': 72,\n",
       " 'Nut Pecan': 73,\n",
       " 'Onion Red': 74,\n",
       " 'Onion Red Peeled': 75,\n",
       " 'Onion White': 76,\n",
       " 'Orange': 77,\n",
       " 'Papaya': 78,\n",
       " 'Passion Fruit': 79,\n",
       " 'Peach': 80,\n",
       " 'Peach 2': 81,\n",
       " 'Peach Flat': 82,\n",
       " 'Pear': 83,\n",
       " 'Pear 2': 84,\n",
       " 'Pear Abate': 85,\n",
       " 'Pear Forelle': 86,\n",
       " 'Pear Kaiser': 87,\n",
       " 'Pear Monster': 88,\n",
       " 'Pear Red': 89,\n",
       " 'Pear Stone': 90,\n",
       " 'Pear Williams': 91,\n",
       " 'Pepino': 92,\n",
       " 'Pepper Green': 93,\n",
       " 'Pepper Orange': 94,\n",
       " 'Pepper Red': 95,\n",
       " 'Pepper Yellow': 96,\n",
       " 'Physalis': 97,\n",
       " 'Physalis with Husk': 98,\n",
       " 'Pineapple': 99,\n",
       " 'Pineapple Mini': 100,\n",
       " 'Pitahaya Red': 101,\n",
       " 'Plum': 102,\n",
       " 'Plum 2': 103,\n",
       " 'Plum 3': 104,\n",
       " 'Pomegranate': 105,\n",
       " 'Pomelo Sweetie': 106,\n",
       " 'Potato Red': 107,\n",
       " 'Potato Red Washed': 108,\n",
       " 'Potato Sweet': 109,\n",
       " 'Potato White': 110,\n",
       " 'Quince': 111,\n",
       " 'Rambutan': 112,\n",
       " 'Raspberry': 113,\n",
       " 'Redcurrant': 114,\n",
       " 'Salak': 115,\n",
       " 'Strawberry': 116,\n",
       " 'Strawberry Wedge': 117,\n",
       " 'Tamarillo': 118,\n",
       " 'Tangelo': 119,\n",
       " 'Tomato 1': 120,\n",
       " 'Tomato 2': 121,\n",
       " 'Tomato 3': 122,\n",
       " 'Tomato 4': 123,\n",
       " 'Tomato Cherry Red': 124,\n",
       " 'Tomato Heart': 125,\n",
       " 'Tomato Maroon': 126,\n",
       " 'Tomato Yellow': 127,\n",
       " 'Tomato not Ripened': 128,\n",
       " 'Walnut': 129,\n",
       " 'Watermelon': 130}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(data_path+'classes.pickle', 'rb') as handle:\n",
    "    input_classes = pickle.load(handle)\n",
    "input_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f715209",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ca16ae59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fruits360CnnModel(\n",
       "  (network): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU()\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU()\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU()\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU()\n",
       "    (14): MaxPool2d(kernel_size=5, stride=5, padding=0, dilation=1, ceil_mode=False)\n",
       "    (15): Flatten(start_dim=1, end_dim=-1)\n",
       "    (16): Linear(in_features=6400, out_features=1024, bias=True)\n",
       "    (17): ReLU()\n",
       "    (18): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (19): ReLU()\n",
       "    (20): Linear(in_features=512, out_features=131, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n",
    "\n",
    "class Fruits360CnnModel(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 64 x 50 x 50\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 128 x 25 x 25\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),#output :256*25*25\n",
    "            nn.MaxPool2d(5, 5), # output: 256 x 5 x 5\n",
    "\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(256*5*5, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 131))\n",
    "            \n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)\n",
    "\n",
    "model = to_device(Fruits360CnnModel(), device)\n",
    "model.load_state_dict(torch.load('C:/Users/vivek/OneDrive/Documents/FarmersMarket/fruits360-cnn.pth', map_location=torch.device('cpu')))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "48d3a3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"C:/Users/vivek/Downloads/pexels-photo-102104.jpeg\"\n",
    "\n",
    "def transform_image(image_bytes):\n",
    "    my_transforms = transforms.Compose([transforms.Resize(100),\n",
    "                                        transforms.CenterCrop(100),\n",
    "                                        transforms.ToTensor()])\n",
    "    image = Image.open(BytesIO(image_bytes))\n",
    "    return my_transforms(image).unsqueeze(0)\n",
    "\n",
    "def get_prediction(image_bytes):\n",
    "    tensor = transform_image(image_bytes=image_bytes)\n",
    "    outputs = model.forward(tensor.to(device))\n",
    "    _, y_hat = outputs.max(1)\n",
    "    return list(input_classes.keys())[list(input_classes.values()).index(y_hat.item())]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4ad191a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'validation':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(100),\n",
    "        transforms.CenterCrop(100),\n",
    "        transforms.ToTensor()\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "84bcd8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(img, model):\n",
    "    # Convert to a batch of 1\n",
    "    xb = to_device(img.unsqueeze(0), device)\n",
    "    # Get predictions from model\n",
    "    yb = model(xb)\n",
    "    # Pick index with highest probability\n",
    "    _, preds  = torch.max(yb, dim=1)\n",
    "    # Retrieve the class label\n",
    "    return list(input_classes.keys())[list(input_classes.values()).index(preds[0].item())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "23f2ff16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physalis with Husk\n"
     ]
    }
   ],
   "source": [
    "with open(\"C:/Users/vivek/Downloads/pexels-photo-102104.jpeg\", 'rb') as f:\n",
    "    image_bytes = f.read()\n",
    "    print(get_prediction(image_bytes=image_bytes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchGPU",
   "language": "python",
   "name": "pytorchgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
